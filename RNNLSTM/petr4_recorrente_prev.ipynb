{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "petr4_recorrente_prev.ipynb",
      "provenance": [],
      "mount_file_id": "1UXnQKGiX8IUcI9E7kvXmraDKwDTz4Xpq",
      "authorship_tag": "ABX9TyOzp98OxG0Ngx6iUy9jN0Ps",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AFBA1993/DeepLearningTutorials/blob/main/RNNLSTM/petr4_recorrente_prev.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tiohEo5I5rui"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base = pd.read_csv('/content/drive/MyDrive/UdemyDeepCSVs/petr4_treinamento.csv')\n",
        "base = base.dropna()\n",
        "base_treinamento = base.iloc[:, 1:7].values"
      ],
      "metadata": {
        "id": "JHAFSkCH54kV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalizador = MinMaxScaler(feature_range=(0,1))\n",
        "base_treinamento_normalizada = normalizador.fit_transform(base_treinamento)"
      ],
      "metadata": {
        "id": "ObhXci-O6P65"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalizador_previsao = MinMaxScaler(feature_range=(0,1))\n",
        "normalizador_previsao.fit_transform(base_treinamento[:,0:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Au3286h5_38",
        "outputId": "f055653a-b55b-4bca-9502-2f1e82e47df5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.76501938],\n",
              "       [0.7562984 ],\n",
              "       [0.78149225],\n",
              "       ...,\n",
              "       [0.57122093],\n",
              "       [0.57655039],\n",
              "       [0.57655039]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previsores = []\n",
        "preco_real = []\n",
        "for i in range(90, 1242):\n",
        "    previsores.append(base_treinamento_normalizada[i-90:i, 0:6])\n",
        "    preco_real.append(base_treinamento_normalizada[i, 0])\n",
        "previsores, preco_real = np.array(previsores), np.array(preco_real)"
      ],
      "metadata": {
        "id": "B_j6yoQy6DeF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor = Sequential()\n",
        "regressor.add(LSTM(units = 100, return_sequences = True, input_shape = (previsores.shape[1], 6)))\n",
        "regressor.add(Dropout(0.3))\n",
        "\n",
        "regressor.add(LSTM(units = 50, return_sequences = True))\n",
        "regressor.add(Dropout(0.3))\n",
        "\n",
        "regressor.add(LSTM(units = 50, return_sequences = True))\n",
        "regressor.add(Dropout(0.3))\n",
        "\n",
        "regressor.add(LSTM(units = 50))\n",
        "regressor.add(Dropout(0.3))\n",
        "\n",
        "regressor.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "\n",
        "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error',\n",
        "                  metrics = ['mean_absolute_error'])"
      ],
      "metadata": {
        "id": "nqIlGWfW6VfG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor = 'loss', min_delta = 1e-10, patience = 10, verbose = 1)\n",
        "rlr = ReduceLROnPlateau(monitor = 'loss', factor = 0.2, patience = 5, verbose = 1)\n",
        "mcp = ModelCheckpoint(filepath = 'pesos.h5', monitor = 'loss', \n",
        "                      save_best_only = True, verbose = 1)\n",
        "regressor.fit(previsores, preco_real, epochs = 100, batch_size = 32,\n",
        "              callbacks = [es, rlr, mcp])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRNGxBI26YAp",
        "outputId": "bdcb5620-0717-4e83-9859-a2402f9f40bc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0172 - mean_absolute_error: 0.0989\n",
            "Epoch 00001: loss improved from inf to 0.01723, saving model to pesos.h5\n",
            "36/36 [==============================] - 12s 174ms/step - loss: 0.0172 - mean_absolute_error: 0.0989 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0059 - mean_absolute_error: 0.0596\n",
            "Epoch 00002: loss improved from 0.01723 to 0.00590, saving model to pesos.h5\n",
            "36/36 [==============================] - 6s 168ms/step - loss: 0.0059 - mean_absolute_error: 0.0596 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0042 - mean_absolute_error: 0.0497\n",
            "Epoch 00003: loss improved from 0.00590 to 0.00416, saving model to pesos.h5\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0042 - mean_absolute_error: 0.0497 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0041 - mean_absolute_error: 0.0487\n",
            "Epoch 00004: loss improved from 0.00416 to 0.00405, saving model to pesos.h5\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0041 - mean_absolute_error: 0.0487 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0038 - mean_absolute_error: 0.0477\n",
            "Epoch 00005: loss improved from 0.00405 to 0.00377, saving model to pesos.h5\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0038 - mean_absolute_error: 0.0477 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0034 - mean_absolute_error: 0.0449\n",
            "Epoch 00006: loss improved from 0.00377 to 0.00342, saving model to pesos.h5\n",
            "36/36 [==============================] - 6s 166ms/step - loss: 0.0034 - mean_absolute_error: 0.0449 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0033 - mean_absolute_error: 0.0446\n",
            "Epoch 00007: loss improved from 0.00342 to 0.00332, saving model to pesos.h5\n",
            "36/36 [==============================] - 6s 168ms/step - loss: 0.0033 - mean_absolute_error: 0.0446 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0029 - mean_absolute_error: 0.0413\n",
            "Epoch 00008: loss improved from 0.00332 to 0.00291, saving model to pesos.h5\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.0029 - mean_absolute_error: 0.0413 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0027 - mean_absolute_error: 0.0398\n",
            "Epoch 00009: loss improved from 0.00291 to 0.00269, saving model to pesos.h5\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.0027 - mean_absolute_error: 0.0398 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0025 - mean_absolute_error: 0.0383\n",
            "Epoch 00010: loss improved from 0.00269 to 0.00250, saving model to pesos.h5\n",
            "36/36 [==============================] - 6s 171ms/step - loss: 0.0025 - mean_absolute_error: 0.0383 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0022 - mean_absolute_error: 0.0362\n",
            "Epoch 00011: loss improved from 0.00250 to 0.00221, saving model to pesos.h5\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0022 - mean_absolute_error: 0.0362 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0022 - mean_absolute_error: 0.0362\n",
            "Epoch 00012: loss improved from 0.00221 to 0.00220, saving model to pesos.h5\n",
            "36/36 [==============================] - 6s 168ms/step - loss: 0.0022 - mean_absolute_error: 0.0362 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0021 - mean_absolute_error: 0.0347\n",
            "Epoch 00013: loss improved from 0.00220 to 0.00206, saving model to pesos.h5\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.0021 - mean_absolute_error: 0.0347 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0019 - mean_absolute_error: 0.0334\n",
            "Epoch 00014: loss improved from 0.00206 to 0.00191, saving model to pesos.h5\n",
            "36/36 [==============================] - 6s 172ms/step - loss: 0.0019 - mean_absolute_error: 0.0334 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0344\n",
            "Epoch 00015: loss did not improve from 0.00191\n",
            "36/36 [==============================] - 6s 167ms/step - loss: 0.0020 - mean_absolute_error: 0.0344 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0339\n",
            "Epoch 00016: loss did not improve from 0.00191\n",
            "36/36 [==============================] - 6s 165ms/step - loss: 0.0020 - mean_absolute_error: 0.0339 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0322\n",
            "Epoch 00017: loss improved from 0.00191 to 0.00178, saving model to pesos.h5\n",
            "36/36 [==============================] - 6s 167ms/step - loss: 0.0018 - mean_absolute_error: 0.0322 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0307\n",
            "Epoch 00018: loss improved from 0.00178 to 0.00165, saving model to pesos.h5\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0016 - mean_absolute_error: 0.0307 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0302\n",
            "Epoch 00019: loss improved from 0.00165 to 0.00164, saving model to pesos.h5\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.0016 - mean_absolute_error: 0.0302 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0319\n",
            "Epoch 00020: loss did not improve from 0.00164\n",
            "36/36 [==============================] - 6s 166ms/step - loss: 0.0017 - mean_absolute_error: 0.0319 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0308\n",
            "Epoch 00021: loss did not improve from 0.00164\n",
            "36/36 [==============================] - 6s 168ms/step - loss: 0.0017 - mean_absolute_error: 0.0308 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0314\n",
            "Epoch 00022: loss did not improve from 0.00164\n",
            "36/36 [==============================] - 6s 166ms/step - loss: 0.0017 - mean_absolute_error: 0.0314 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0297\n",
            "Epoch 00023: loss improved from 0.00164 to 0.00153, saving model to pesos.h5\n",
            "36/36 [==============================] - 6s 167ms/step - loss: 0.0015 - mean_absolute_error: 0.0297 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0287\n",
            "Epoch 00024: loss improved from 0.00153 to 0.00143, saving model to pesos.h5\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0014 - mean_absolute_error: 0.0287 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0295\n",
            "Epoch 00025: loss did not improve from 0.00143\n",
            "36/36 [==============================] - 6s 165ms/step - loss: 0.0015 - mean_absolute_error: 0.0295 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0294\n",
            "Epoch 00026: loss did not improve from 0.00143\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0015 - mean_absolute_error: 0.0294 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0287\n",
            "Epoch 00027: loss improved from 0.00143 to 0.00143, saving model to pesos.h5\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.0014 - mean_absolute_error: 0.0287 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0304\n",
            "Epoch 00028: loss did not improve from 0.00143\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0016 - mean_absolute_error: 0.0304 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0298\n",
            "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "\n",
            "Epoch 00029: loss did not improve from 0.00143\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0016 - mean_absolute_error: 0.0298 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0267\n",
            "Epoch 00030: loss improved from 0.00143 to 0.00132, saving model to pesos.h5\n",
            "36/36 [==============================] - 6s 166ms/step - loss: 0.0013 - mean_absolute_error: 0.0267 - lr: 2.0000e-04\n",
            "Epoch 31/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0260\n",
            "Epoch 00031: loss improved from 0.00132 to 0.00124, saving model to pesos.h5\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.0012 - mean_absolute_error: 0.0260 - lr: 2.0000e-04\n",
            "Epoch 32/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0269\n",
            "Epoch 00032: loss did not improve from 0.00124\n",
            "36/36 [==============================] - 6s 166ms/step - loss: 0.0013 - mean_absolute_error: 0.0269 - lr: 2.0000e-04\n",
            "Epoch 33/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0272\n",
            "Epoch 00033: loss did not improve from 0.00124\n",
            "36/36 [==============================] - 6s 168ms/step - loss: 0.0013 - mean_absolute_error: 0.0272 - lr: 2.0000e-04\n",
            "Epoch 34/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0262\n",
            "Epoch 00034: loss did not improve from 0.00124\n",
            "36/36 [==============================] - 6s 166ms/step - loss: 0.0013 - mean_absolute_error: 0.0262 - lr: 2.0000e-04\n",
            "Epoch 35/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0257\n",
            "Epoch 00035: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "\n",
            "Epoch 00035: loss improved from 0.00124 to 0.00123, saving model to pesos.h5\n",
            "36/36 [==============================] - 6s 168ms/step - loss: 0.0012 - mean_absolute_error: 0.0257 - lr: 2.0000e-04\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0260\n",
            "Epoch 00036: loss did not improve from 0.00123\n",
            "36/36 [==============================] - 6s 167ms/step - loss: 0.0013 - mean_absolute_error: 0.0260 - lr: 4.0000e-05\n",
            "Epoch 37/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0251\n",
            "Epoch 00037: loss improved from 0.00123 to 0.00114, saving model to pesos.h5\n",
            "36/36 [==============================] - 6s 168ms/step - loss: 0.0011 - mean_absolute_error: 0.0251 - lr: 4.0000e-05\n",
            "Epoch 38/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0257\n",
            "Epoch 00038: loss did not improve from 0.00114\n",
            "36/36 [==============================] - 6s 166ms/step - loss: 0.0012 - mean_absolute_error: 0.0257 - lr: 4.0000e-05\n",
            "Epoch 39/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0258\n",
            "Epoch 00039: loss did not improve from 0.00114\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0012 - mean_absolute_error: 0.0258 - lr: 4.0000e-05\n",
            "Epoch 40/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0251\n",
            "Epoch 00040: loss did not improve from 0.00114\n",
            "36/36 [==============================] - 6s 168ms/step - loss: 0.0011 - mean_absolute_error: 0.0251 - lr: 4.0000e-05\n",
            "Epoch 41/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0255\n",
            "Epoch 00041: loss did not improve from 0.00114\n",
            "36/36 [==============================] - 6s 167ms/step - loss: 0.0012 - mean_absolute_error: 0.0255 - lr: 4.0000e-05\n",
            "Epoch 42/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0256\n",
            "Epoch 00042: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "\n",
            "Epoch 00042: loss did not improve from 0.00114\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.0012 - mean_absolute_error: 0.0256 - lr: 4.0000e-05\n",
            "Epoch 43/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0259\n",
            "Epoch 00043: loss did not improve from 0.00114\n",
            "36/36 [==============================] - 6s 166ms/step - loss: 0.0012 - mean_absolute_error: 0.0259 - lr: 8.0000e-06\n",
            "Epoch 44/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0256\n",
            "Epoch 00044: loss did not improve from 0.00114\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0012 - mean_absolute_error: 0.0256 - lr: 8.0000e-06\n",
            "Epoch 45/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0251\n",
            "Epoch 00045: loss improved from 0.00114 to 0.00112, saving model to pesos.h5\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0011 - mean_absolute_error: 0.0251 - lr: 8.0000e-06\n",
            "Epoch 46/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0244\n",
            "Epoch 00046: loss did not improve from 0.00112\n",
            "36/36 [==============================] - 6s 168ms/step - loss: 0.0011 - mean_absolute_error: 0.0244 - lr: 8.0000e-06\n",
            "Epoch 47/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0253\n",
            "Epoch 00047: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
            "\n",
            "Epoch 00047: loss did not improve from 0.00112\n",
            "36/36 [==============================] - 6s 168ms/step - loss: 0.0012 - mean_absolute_error: 0.0253 - lr: 8.0000e-06\n",
            "Epoch 48/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0258\n",
            "Epoch 00048: loss did not improve from 0.00112\n",
            "36/36 [==============================] - 6s 167ms/step - loss: 0.0012 - mean_absolute_error: 0.0258 - lr: 1.6000e-06\n",
            "Epoch 49/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0257\n",
            "Epoch 00049: loss did not improve from 0.00112\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0012 - mean_absolute_error: 0.0257 - lr: 1.6000e-06\n",
            "Epoch 50/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0253\n",
            "Epoch 00050: loss did not improve from 0.00112\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0012 - mean_absolute_error: 0.0253 - lr: 1.6000e-06\n",
            "Epoch 51/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0252\n",
            "Epoch 00051: loss did not improve from 0.00112\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.0012 - mean_absolute_error: 0.0252 - lr: 1.6000e-06\n",
            "Epoch 52/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0262\n",
            "Epoch 00052: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
            "\n",
            "Epoch 00052: loss did not improve from 0.00112\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.0012 - mean_absolute_error: 0.0262 - lr: 1.6000e-06\n",
            "Epoch 53/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0252\n",
            "Epoch 00053: loss did not improve from 0.00112\n",
            "36/36 [==============================] - 6s 172ms/step - loss: 0.0011 - mean_absolute_error: 0.0252 - lr: 3.2000e-07\n",
            "Epoch 54/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0258\n",
            "Epoch 00054: loss did not improve from 0.00112\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.0012 - mean_absolute_error: 0.0258 - lr: 3.2000e-07\n",
            "Epoch 55/100\n",
            "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0259\n",
            "Epoch 00055: loss did not improve from 0.00112\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0012 - mean_absolute_error: 0.0259 - lr: 3.2000e-07\n",
            "Epoch 00055: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd81a43dd90>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_teste = pd.read_csv('/content/drive/MyDrive/UdemyDeepCSVs/petr4_teste.csv')\n",
        "preco_real_teste = base_teste.iloc[:, 1:2].values\n",
        "frames = [base, base_teste]\n",
        "base_completa = pd.concat(frames)\n",
        "base_completa = base_completa.drop('Date', axis = 1)"
      ],
      "metadata": {
        "id": "r2Iyezb670br"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entradas = base_completa[len(base_completa) - len(base_teste) - 90:].values\n",
        "entradas = normalizador.transform(entradas)\n",
        "\n",
        "X_teste = []\n",
        "for i in range(90, 112):\n",
        "    X_teste.append(entradas[i-90:i, 0:6])\n",
        "X_teste = np.array(X_teste)\n"
      ],
      "metadata": {
        "id": "hnRWOAUB8DRT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "previsoes = regressor.predict(X_teste)\n",
        "previsoes = normalizador_previsao.inverse_transform(previsoes)"
      ],
      "metadata": {
        "id": "sV2jz_3r8GHX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "previsoes.mean()\n",
        "preco_real_teste.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFfgl_n08MIP",
        "outputId": "eacd3439-7295-4201-e648-f91aa900748b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17.87454563636364"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(preco_real_teste, color = 'red', label = 'Preço real')\n",
        "plt.plot(previsoes, color = 'blue', label = 'Previsões')\n",
        "plt.title('Previsão preço das ações')\n",
        "plt.xlabel('Tempo')\n",
        "plt.ylabel('Valor Yahoo')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "0EDMnRvy8OaJ",
        "outputId": "5db47923-6063-4452-9849-2f118f9cfee3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}